{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER regex",
      "provenance": [],
      "authorship_tag": "ABX9TyPajv/paYvxSZRPeIuFPXKf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SPORTNERHSE/SPORTNER/blob/master/NER_regex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtxI4oX9Tngw",
        "colab_type": "code",
        "outputId": "3c5ab15f-8dce-4545-a71a-f00db9586c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "!pip install pymystem3==0.1.10\n",
        "!pip install pymorphy2[fast]\n",
        "!pip install spacy\n",
        "!pip install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymystem3==0.1.10\n",
            "  Downloading https://files.pythonhosted.org/packages/51/56/57e550b53587719e92330a79c7c0f555402d953b00700efae6d5ca53cdef/pymystem3-0.1.10-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3==0.1.10) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (2019.11.28)\n",
            "Installing collected packages: pymystem3\n",
            "  Found existing installation: pymystem3 0.2.0\n",
            "    Uninstalling pymystem3-0.2.0:\n",
            "      Successfully uninstalled pymystem3-0.2.0\n",
            "Successfully installed pymystem3-0.1.10\n",
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 8.1MB/s \n",
            "\u001b[?25hCollecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz (371kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 44.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp36-cp36m-linux_x86_64.whl size=843813 sha256=23e03b3e7727601cd7299bf5fc8e5bf95d59cbcdedd4c513af2c3562b43d5e95\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
            "Successfully built DAWG\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.5)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56ouCM7e5QfA",
        "colab_type": "code",
        "outputId": "49549ede-7bb8-407d-ab18-250298c2e063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr0v2M14SGMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "from gensim.utils import tokenize\n",
        "from gensim.summarization.textcleaner import split_sentences\n",
        "from nltk import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from pymystem3 import Mystem\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "import re, os, json\n",
        "import regex\n",
        "import spacy\n",
        "import nltk\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "mystem = Mystem()\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmdCwIFi4mu3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HRoIYIq4sOY",
        "colab_type": "code",
        "outputId": "94a75b4c-99b6-4ddc-8e40-87e2be65d3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "df = pd.read_csv('result.tar.gz', sep='\\t', error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 37039: expected 12 fields, saw 15\\nSkipping line 45611: expected 12 fields, saw 15\\n'\n",
            "b'Skipping line 354339: expected 12 fields, saw 18\\nSkipping line 360804: expected 12 fields, saw 102\\nSkipping line 360819: expected 12 fields, saw 78\\nSkipping line 379126: expected 12 fields, saw 14\\nSkipping line 444446: expected 12 fields, saw 16\\nSkipping line 449079: expected 12 fields, saw 16\\nSkipping line 450250: expected 12 fields, saw 15\\n'\n",
            "b'Skipping line 481374: expected 12 fields, saw 18\\nSkipping line 510619: expected 12 fields, saw 20\\nSkipping line 512271: expected 12 fields, saw 14\\nSkipping line 514317: expected 12 fields, saw 15\\nSkipping line 519707: expected 12 fields, saw 40\\n'\n",
            "b'Skipping line 538495: expected 12 fields, saw 13\\n'\n",
            "b'Skipping line 765901: expected 12 fields, saw 56\\nSkipping line 773310: expected 12 fields, saw 43\\n'\n",
            "b'Skipping line 805899: expected 12 fields, saw 13\\nSkipping line 868492: expected 12 fields, saw 21\\nSkipping line 871801: expected 12 fields, saw 16\\n'\n",
            "b'Skipping line 903099: expected 12 fields, saw 13\\nSkipping line 903150: expected 12 fields, saw 13\\nSkipping line 903155: expected 12 fields, saw 13\\nSkipping line 926112: expected 12 fields, saw 13\\n'\n",
            "b'Skipping line 952511: expected 12 fields, saw 14\\nSkipping line 954085: expected 12 fields, saw 13\\nSkipping line 956504: expected 12 fields, saw 40\\nSkipping line 981135: expected 12 fields, saw 13\\nSkipping line 983460: expected 12 fields, saw 16\\nSkipping line 985000: expected 12 fields, saw 15\\nSkipping line 986754: expected 12 fields, saw 13\\nSkipping line 986828: expected 12 fields, saw 13\\n'\n",
            "b'Skipping line 1334533: expected 12 fields, saw 13\\nSkipping line 1337066: expected 12 fields, saw 16\\nSkipping line 1343528: expected 12 fields, saw 13\\nSkipping line 1351606: expected 12 fields, saw 14\\n'\n",
            "b'Skipping line 1376142: expected 12 fields, saw 16\\nSkipping line 1376408: expected 12 fields, saw 15\\nSkipping line 1389213: expected 12 fields, saw 59\\nSkipping line 1401635: expected 12 fields, saw 23\\n'\n",
            "b'Skipping line 1762082: expected 12 fields, saw 13\\nSkipping line 1763155: expected 12 fields, saw 16\\n'\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttZgbETposgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop([\"url\", \"video_url\", \"source_name\", \"author_name\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxxgl9yso0D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()\n",
        "df = df.drop_duplicates()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71kPBPAmo3R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzHiyx6Jo9J3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['result.tsv'][12]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOkHZg5no-if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    \n",
        "    normalized_text = [(word.strip(punctuation)) for word \\\n",
        "                                                            in text.lower().split()]\n",
        "    normalized_text = [word for word in normalized_text if word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM1q1wf56OuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def preprocess(text):\n",
        "    text = nltk.word_tokenize(text)\n",
        "    text = nltk.pos_tag(text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWNg_lb9Ng_l",
        "colab_type": "code",
        "outputId": "159bd5ca-fd84-43c5-8c30-d2854da61323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#text = preprocess('result.tar.gz')\n",
        "text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('result.tar.gz', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IzD_xvvlbY_",
        "colab_type": "code",
        "outputId": "da8ce38c-c3a5-431e-8ccf-6bfcf604fc8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "def titles(fileid=None,corpus='result.tar.gz'):\n",
        "    \"\"\"\n",
        "    Use a regular expression to extract the titles from the corpus.\n",
        "    \"\"\"\n",
        "    pattern = re.compile(r'^(.*)[\\s]+[\\s]?(.*)?') \n",
        "\n",
        "    if fileid is not None:\n",
        "        match = pattern.search('result.tar.gz'.raw(fileid))\n",
        "        yield \" \".join(map(lambda s: s.strip(), match.groups()))\n",
        "    else:\n",
        "        for fileid in corpus.fileids():\n",
        "            # Search for a pattern match\n",
        "            match = pattern.search(corpus.raw(fileid))\n",
        "\n",
        "            if match:\n",
        "                # If we find one, yield the space joined groups.\n",
        "                yield \" \".join(map(lambda s: s.strip(), match.groups()))\n",
        "                \n",
        "for idx, title in enumerate(titles()):\n",
        "  print title\n",
        "  if idx >= 10:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-63-8a87b550650d>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    print title\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(title)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILLORrylncpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sectpull(fileids=None, section=None, corpus='result.tar.gz'):\n",
        "    \"\"\"\n",
        "    Uses a regular expression to pull sections from a file:\n",
        "        - \"top\": everything until the references section\n",
        "        - \"ref\": the references and anything that follows.\n",
        "    Yields the text as top, ref respectively.\n",
        "    \"\"\"\n",
        "\n",
        "    # Select either a single fileid or a list of fileids\n",
        "    fileids = fileids or corpus.fileids()\n",
        "    if section == None:\n",
        "        section = None\n",
        "    elif section == 'references':\n",
        "        section = re.compile('(?<=' + 'REFERENCES' + ')(.+)')\n",
        "    elif section == 'body':\n",
        "        section = re.compile(\"(.+?)(?=\"+'REFERENCES'+ \")\")\n",
        "    elif section == 'top':\n",
        "        section = [\"url\", \"video_url\", \"source_name\", \"author_name\"]\n",
        "        for sect in section:\n",
        "            try:\n",
        "                section = re.compile(\"(.+?)(?=\"+sect+ \")\")\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    # Iterate through all text for each file id.\n",
        "    for fileid in fileids:\n",
        "        text   = corpus.raw(fileid)\n",
        "\n",
        "    # Extract the text and search for the section target\n",
        "        if section == None:\n",
        "            target = re.sub('[\\s]', \" \", text)\n",
        "        else:\n",
        "            text   = re.sub('[\\s]', \" \", text)\n",
        "            target = section.search(text)\n",
        "        if target:\n",
        "            yield fileid, target.group(0), target.group(1)\n",
        "\n",
        "\n",
        "def refstats(fileids=None, section=None, corpus='result.tar.gz'):\n",
        "    \"\"\"\n",
        "    Code to pull only the references section, store a character count, number\n",
        "    of references, as well as a \"words per reference\" count.\n",
        "    Pass either a specific document id, a list of ids, or None for all ids.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create reference number to match pattern\n",
        "    refnum  = re.compile(r'\\[[0-9]{1,3}\\]', re.I)\n",
        "\n",
        "    for fileid, top, refs in sectpull(fileids, section, corpus):\n",
        "      # Yield the statistics about the references\n",
        "        n_refs = len(set((refnum.findall(refs))))\n",
        "        \n",
        "        words  = sum(1 for word in nltk.word_tokenize(refs))\n",
        "        wp_ref = float(words) / float(n_refs) if n_refs else 0\n",
        "        \n",
        "        # Yield the data from the generator\n",
        "        yield (fileid, len(refs), n_refs, wp_ref)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LQxdigDqQyC",
        "colab_type": "code",
        "outputId": "6e0b7527-06bd-4cd2-c2d3-1ed7d386d9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "From tabulate import tabulate\n",
        "from operator import itemgetter\n",
        "import random\n",
        "\n",
        "# Create table sorted by number of references\n",
        "table   = \n",
        "sorted(list(refstats(random.sample(kddcorpus.fileids(),15),section='body')))\n",
        "\n",
        "# Print the table with headers\n",
        "headers = ('File', 'Characters', 'References', 'Words per Reference')\n",
        "\n",
        "print(tabulate(table, headers=headers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-9f9556b0625c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    From tabulate import tabulate\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}
