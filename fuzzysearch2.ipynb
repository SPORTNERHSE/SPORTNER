{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk import word_tokenize\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation \n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 37039: expected 12 fields, saw 15\\nSkipping line 45611: expected 12 fields, saw 15\\n'\n",
      "b'Skipping line 354339: expected 12 fields, saw 18\\nSkipping line 360804: expected 12 fields, saw 102\\nSkipping line 360819: expected 12 fields, saw 78\\nSkipping line 379126: expected 12 fields, saw 14\\nSkipping line 444446: expected 12 fields, saw 16\\nSkipping line 449079: expected 12 fields, saw 16\\nSkipping line 450250: expected 12 fields, saw 15\\n'\n",
      "b'Skipping line 481374: expected 12 fields, saw 18\\nSkipping line 510619: expected 12 fields, saw 20\\nSkipping line 512271: expected 12 fields, saw 14\\nSkipping line 514317: expected 12 fields, saw 15\\nSkipping line 519707: expected 12 fields, saw 40\\n'\n",
      "b'Skipping line 538495: expected 12 fields, saw 13\\n'\n",
      "b'Skipping line 765901: expected 12 fields, saw 56\\nSkipping line 773310: expected 12 fields, saw 43\\n'\n",
      "b'Skipping line 805899: expected 12 fields, saw 13\\nSkipping line 868492: expected 12 fields, saw 21\\nSkipping line 871801: expected 12 fields, saw 16\\n'\n",
      "b'Skipping line 903099: expected 12 fields, saw 13\\nSkipping line 903150: expected 12 fields, saw 13\\nSkipping line 903155: expected 12 fields, saw 13\\nSkipping line 926112: expected 12 fields, saw 13\\n'\n",
      "b'Skipping line 952511: expected 12 fields, saw 14\\nSkipping line 954085: expected 12 fields, saw 13\\nSkipping line 956504: expected 12 fields, saw 40\\nSkipping line 981135: expected 12 fields, saw 13\\nSkipping line 983460: expected 12 fields, saw 16\\nSkipping line 985000: expected 12 fields, saw 15\\nSkipping line 986754: expected 12 fields, saw 13\\nSkipping line 986828: expected 12 fields, saw 13\\n'\n",
      "b'Skipping line 1334533: expected 12 fields, saw 13\\nSkipping line 1337066: expected 12 fields, saw 16\\nSkipping line 1343528: expected 12 fields, saw 13\\nSkipping line 1351606: expected 12 fields, saw 14\\n'\n",
      "b'Skipping line 1376142: expected 12 fields, saw 16\\nSkipping line 1376408: expected 12 fields, saw 15\\nSkipping line 1389213: expected 12 fields, saw 59\\nSkipping line 1401635: expected 12 fields, saw 23\\n'\n",
      "b'Skipping line 1762082: expected 12 fields, saw 13\\nSkipping line 1763155: expected 12 fields, saw 16\\n'\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('result_tar.gz', compression='gzip', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"url\", \"video_url\", \"source_name\", \"author_name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result.tsv</th>\n",
       "      <th>odd</th>\n",
       "      <th>tip_name</th>\n",
       "      <th>bookmaker_name</th>\n",
       "      <th>match_date_time</th>\n",
       "      <th>league_name_in_russian</th>\n",
       "      <th>team_of_season_1_name_in_russian</th>\n",
       "      <th>team_of_season_2_name_in_russian</th>\n",
       "      <th>fuzzy_match_for_leagues</th>\n",
       "      <th>fuzzy_match_for_bookmakers2</th>\n",
       "      <th>fuzzy_match_for_tipname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Сборная Турции продолжает свою дорогу на Чемпи...</td>\n",
       "      <td>1.65</td>\n",
       "      <td>- 1,5</td>\n",
       "      <td>Олимп</td>\n",
       "      <td>2019-06-02 18:00:00</td>\n",
       "      <td>Международные товарищеские матчи</td>\n",
       "      <td>Турция</td>\n",
       "      <td>Узбекистан</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Двадцать девятого числа состоится один весьма ...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>– тотал меньше 2,5</td>\n",
       "      <td>Winline</td>\n",
       "      <td>2019-06-28 23:20:00</td>\n",
       "      <td>Кубок Америки</td>\n",
       "      <td>Колумбия</td>\n",
       "      <td>Чили</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>АЗ Алкмар В первом матче голландский клуб созд...</td>\n",
       "      <td>1.85</td>\n",
       "      <td>АЗ Алкмар забьет в обоих таймах</td>\n",
       "      <td>Лига Ставок</td>\n",
       "      <td>2019-08-15 18:30:00</td>\n",
       "      <td>Лига Европы УЕФА</td>\n",
       "      <td>АЗ Алкмаар</td>\n",
       "      <td>Мариуполь</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>«Сачхере» — «Абердин» И тот, и другой клуб оде...</td>\n",
       "      <td>1.45</td>\n",
       "      <td>Айнтрахт - 3 и более гола</td>\n",
       "      <td>Лига Ставок</td>\n",
       "      <td>2019-07-25 17:00:00</td>\n",
       "      <td>Лига Европы УЕФА</td>\n",
       "      <td>Флора</td>\n",
       "      <td>Айнтрахт Франкфурт</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Я предполагаю ничью в этом матче с забитыми мя...</td>\n",
       "      <td>5</td>\n",
       "      <td>Арсенал забьет первым и не выиграет</td>\n",
       "      <td>1xСтавка</td>\n",
       "      <td>2019-05-09 19:00:00</td>\n",
       "      <td>Лига Европы УЕФА</td>\n",
       "      <td>Валенсия</td>\n",
       "      <td>Арсенал</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Июль подходит к концу. Скоро мадридское дерби ...</td>\n",
       "      <td>1.62</td>\n",
       "      <td>Атлетико забьет 1 или 2 гола: да</td>\n",
       "      <td>Фонбет</td>\n",
       "      <td>2019-07-27 00:06:00</td>\n",
       "      <td>Международный Кубок чемпионов</td>\n",
       "      <td>Реал Мадрид</td>\n",
       "      <td>Атлетико Мадрид</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>«Ахмат», который доставил много проблем команд...</td>\n",
       "      <td>1.71</td>\n",
       "      <td>Ахмат забьет 1 или 2 гола: да</td>\n",
       "      <td>Пари-Матч</td>\n",
       "      <td>2019-07-14 18:30:00</td>\n",
       "      <td>Премьер-Лига</td>\n",
       "      <td>Ахмат</td>\n",
       "      <td>Краснодар</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Никто толком не представляет, в каких составах...</td>\n",
       "      <td>2.45</td>\n",
       "      <td>Бавария забьет в обоих таймах</td>\n",
       "      <td>Лига Ставок</td>\n",
       "      <td>2019-07-18 03:00:00</td>\n",
       "      <td>Международный Кубок чемпионов</td>\n",
       "      <td>Арсенал</td>\n",
       "      <td>Бавария</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Матч вроде бы товарищеский, но - это и репутац...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Барселона забьет в каждом тайме</td>\n",
       "      <td>Лига Ставок</td>\n",
       "      <td>2019-07-23 10:30:00</td>\n",
       "      <td>Клубные товарищеские матчи</td>\n",
       "      <td>Барселона</td>\n",
       "      <td>Челси</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Беларусь – Эстония: прогноз и ставка на матч 1...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Беларусь индивидуальный тотал больше 1,5</td>\n",
       "      <td>Пари-Матч</td>\n",
       "      <td>2019-10-10 16:00:00</td>\n",
       "      <td>Чемпионат Европы. Квалификация</td>\n",
       "      <td>Беларусь</td>\n",
       "      <td>Эстония</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          result.tsv   odd  \\\n",
       "0  Сборная Турции продолжает свою дорогу на Чемпи...  1.65   \n",
       "1  Двадцать девятого числа состоится один весьма ...  1.52   \n",
       "2  АЗ Алкмар В первом матче голландский клуб созд...  1.85   \n",
       "3  «Сачхере» — «Абердин» И тот, и другой клуб оде...  1.45   \n",
       "4  Я предполагаю ничью в этом матче с забитыми мя...     5   \n",
       "5  Июль подходит к концу. Скоро мадридское дерби ...  1.62   \n",
       "6  «Ахмат», который доставил много проблем команд...  1.71   \n",
       "7  Никто толком не представляет, в каких составах...  2.45   \n",
       "8  Матч вроде бы товарищеский, но - это и репутац...  3.25   \n",
       "9  Беларусь – Эстония: прогноз и ставка на матч 1...   1.9   \n",
       "\n",
       "                                   tip_name bookmaker_name  \\\n",
       "0                                     - 1,5          Олимп   \n",
       "1                        – тотал меньше 2,5        Winline   \n",
       "2           АЗ Алкмар забьет в обоих таймах    Лига Ставок   \n",
       "3                 Айнтрахт - 3 и более гола    Лига Ставок   \n",
       "4       Арсенал забьет первым и не выиграет       1xСтавка   \n",
       "5          Атлетико забьет 1 или 2 гола: да         Фонбет   \n",
       "6             Ахмат забьет 1 или 2 гола: да      Пари-Матч   \n",
       "7             Бавария забьет в обоих таймах    Лига Ставок   \n",
       "8           Барселона забьет в каждом тайме    Лига Ставок   \n",
       "9  Беларусь индивидуальный тотал больше 1,5      Пари-Матч   \n",
       "\n",
       "       match_date_time            league_name_in_russian  \\\n",
       "0  2019-06-02 18:00:00  Международные товарищеские матчи   \n",
       "1  2019-06-28 23:20:00                     Кубок Америки   \n",
       "2  2019-08-15 18:30:00                  Лига Европы УЕФА   \n",
       "3  2019-07-25 17:00:00                  Лига Европы УЕФА   \n",
       "4  2019-05-09 19:00:00                  Лига Европы УЕФА   \n",
       "5  2019-07-27 00:06:00     Международный Кубок чемпионов   \n",
       "6  2019-07-14 18:30:00                      Премьер-Лига   \n",
       "7  2019-07-18 03:00:00     Международный Кубок чемпионов   \n",
       "8  2019-07-23 10:30:00        Клубные товарищеские матчи   \n",
       "9  2019-10-10 16:00:00    Чемпионат Европы. Квалификация   \n",
       "\n",
       "  team_of_season_1_name_in_russian team_of_season_2_name_in_russian  \\\n",
       "0                           Турция                       Узбекистан   \n",
       "1                         Колумбия                             Чили   \n",
       "2                       АЗ Алкмаар                        Мариуполь   \n",
       "3                            Флора               Айнтрахт Франкфурт   \n",
       "4                         Валенсия                          Арсенал   \n",
       "5                      Реал Мадрид                  Атлетико Мадрид   \n",
       "6                            Ахмат                        Краснодар   \n",
       "7                          Арсенал                          Бавария   \n",
       "8                        Барселона                            Челси   \n",
       "9                         Беларусь                          Эстония   \n",
       "\n",
       "   fuzzy_match_for_leagues  fuzzy_match_for_bookmakers2  \\\n",
       "0                      1.0                          0.0   \n",
       "1                      1.0                          0.0   \n",
       "2                      0.0                          1.0   \n",
       "3                      1.0                          0.0   \n",
       "4                      0.0                          1.0   \n",
       "5                      1.0                          1.0   \n",
       "6                      1.0                          1.0   \n",
       "7                      0.0                          0.0   \n",
       "8                      1.0                          0.0   \n",
       "9                      0.0                          1.0   \n",
       "\n",
       "   fuzzy_match_for_tipname  \n",
       "0                      1.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "5                      0.0  \n",
       "6                      1.0  \n",
       "7                      0.0  \n",
       "8                      0.0  \n",
       "9                      0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = get_stop_words('ru')\n",
    "stop_words_list2 = stopwords.words('russian')\n",
    "full_stops = set(stop_words_list + stop_words_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нечеткий поиск по командам 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 35min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens = []\n",
    "teams1_match = np.zeros(df.shape[0])\n",
    "for i, text in enumerate(df['result.tsv'].values):\n",
    "    txt_tokens = []\n",
    "    txt_tokens.append(word_tokenize(text))\n",
    "    for text in txt_tokens:\n",
    "        for t in text:\n",
    "            if fuzz.ratio(df['team_of_season_1_name_in_russian'][i], t) > 70:\n",
    "                teams1_match[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_teams1'] = teams1_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_teams1'].shape[0]\n",
    "print(all_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330689\n"
     ]
    }
   ],
   "source": [
    "success = df[df['fuzzy_match_for_teams1'] == 1].shape[0]\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47045843837315837\n"
     ]
    }
   ],
   "source": [
    "fuzzyline_team1 = success / all_vals\n",
    "print(fuzzyline_team1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нечеткий поиск по командам 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 30min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens = []\n",
    "teams2_match = np.zeros(df.shape[0])\n",
    "for i, text in enumerate(df['result.tsv'].values):\n",
    "    txt_tokens = []\n",
    "    txt_tokens.append(word_tokenize(text))\n",
    "    for text in txt_tokens:\n",
    "        for t in text:\n",
    "            if fuzz.ratio(df['team_of_season_2_name_in_russian'][i], t) > 70:\n",
    "                teams2_match[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_teams2'] = teams2_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_teams2'].shape[0]\n",
    "print(all_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321167\n"
     ]
    }
   ],
   "source": [
    "success = df[df['fuzzy_match_for_teams2'] == 1].shape[0]\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzyline_team2 = success / all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4569118575972958\n"
     ]
    }
   ],
   "source": [
    "print(fuzzyline_team2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нечеткий поиск по лигам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без нграммов (попробовать снова)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 20min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens = []\n",
    "leagues_match = np.zeros(df.shape[0])\n",
    "for i, text in enumerate(df['result.tsv'].values):\n",
    "    txt_tokens = []\n",
    "    txt_tokens.append(word_tokenize(text))\n",
    "    for text in txt_tokens:\n",
    "        for t in text:\n",
    "            if t not in full_stops:\n",
    "                if fuzz.ratio(df['league_name_in_russian'][i], t) > 60:\n",
    "                    leagues_match[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_leagues'] = leagues_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n",
      "88254\n",
      "0.1255555492326165\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_leagues'].shape[0]\n",
    "print(all_vals)\n",
    "success = df[df['fuzzy_match_for_leagues'] == 1].shape[0]\n",
    "print(success)\n",
    "fuzzyline_leagues = success / all_vals\n",
    "print(fuzzyline_leagues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С использованием нграммов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702908it [3:36:13, 54.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 36min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "leagues_match = np.zeros(df.shape[0])\n",
    "for i, text in tqdm(enumerate(df['result.tsv'].values)):\n",
    "    n_words_league = len(word_tokenize(df['league_name_in_russian'][i]))\n",
    "    #print(n_words_league)\n",
    "    N = n_words_league\n",
    "    words = word_tokenize(text)\n",
    "    grams = [words[i:i+N] for i in range(len(words)-N+1)]\n",
    "    #print(i)\n",
    "    #print(grams)\n",
    "    for gram in grams: \n",
    "        str1 = \" \"\n",
    "        joined_gram = str1.join(gram)\n",
    "        #print(joined_gram)\n",
    "        if fuzz.ratio(df['league_name_in_russian'][i], joined_gram) > 60:\n",
    "            #print(df['league_name_in_russian'][i], joined_gram)\n",
    "            leagues_match[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_leagues'] = leagues_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n",
      "128578\n",
      "0.18292294297404496\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_leagues'].shape[0]\n",
    "print(all_vals)\n",
    "success = df[df['fuzzy_match_for_leagues'] == 1].shape[0]\n",
    "print(success)\n",
    "fuzzyline_leagues = success / all_vals\n",
    "print(fuzzyline_leagues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нечеткий поиск по букмекерам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант без нграммов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 24min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens = []\n",
    "bookmaker_match = np.zeros(df.shape[0])\n",
    "for i, text in enumerate(df['result.tsv'].values):\n",
    "    txt_tokens = []\n",
    "    txt_tokens.append(word_tokenize(text))\n",
    "    for text in txt_tokens:\n",
    "        for t in text:\n",
    "            if fuzz.ratio(df['bookmaker_name'][i], t) > 70:\n",
    "                bookmaker_match[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_bookmakers1'] = bookmaker_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n",
      "1596\n",
      "0.002270567414227751\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_bookmakers1'].shape[0]\n",
    "print(all_vals)\n",
    "success = df[df['fuzzy_match_for_bookmakers1'] == 1].shape[0]\n",
    "print(success)\n",
    "fuzzyline_bookmakers = success / all_vals\n",
    "print(fuzzyline_bookmakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант с нграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702908it [2:42:52, 71.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 42min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "bookmaker_match = np.zeros(df.shape[0])\n",
    "for i, text in tqdm(enumerate(df['result.tsv'].values)):\n",
    "    n_words_bookmaker = len(word_tokenize(df['bookmaker_name'][i]))\n",
    "    #print(n_words_league)\n",
    "    N = n_words_bookmaker\n",
    "    words = word_tokenize(text)\n",
    "    grams = [words[i:i+N] for i in range(len(words)-N+1)]\n",
    "    #print(i)\n",
    "    #print(grams)\n",
    "    for gram in grams: \n",
    "        str1 = \" \"\n",
    "        joined_gram = str1.join(gram)\n",
    "        #print(joined_gram)\n",
    "        if fuzz.ratio(df['bookmaker_name'][i], joined_gram) > 60:\n",
    "            #print(df['league_name_in_russian'][i], joined_gram)\n",
    "            bookmaker_match[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_bookmakers2'] = bookmaker_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n",
      "60190\n",
      "0.0856299828711581\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_bookmakers2'].shape[0]\n",
    "print(all_vals)\n",
    "success = df[df['fuzzy_match_for_bookmakers2'] == 1].shape[0]\n",
    "print(success)\n",
    "fuzzyline_bookmakers = success / all_vals\n",
    "print(fuzzyline_bookmakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нечеткий поиск по tip_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C нграммами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702908it [3:29:25, 55.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 29min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tipname_match = np.zeros(df.shape[0])\n",
    "for i, text in tqdm(enumerate(df['result.tsv'].values)):\n",
    "    n_words_tipname = len(word_tokenize(df['tip_name'][i]))\n",
    "    #print(n_words_league)\n",
    "    N = n_words_tipname\n",
    "    words = word_tokenize(text)\n",
    "    grams = [words[i:i+N] for i in range(len(words)-N+1)]\n",
    "    #print(i)\n",
    "    #print(grams)\n",
    "    for gram in grams: \n",
    "        str1 = \" \"\n",
    "        joined_gram = str1.join(gram)\n",
    "        #print(joined_gram)\n",
    "        if fuzz.ratio(df['tip_name'][i], joined_gram) > 60:\n",
    "            #print(df['league_name_in_russian'][i], joined_gram)\n",
    "            tipname_match[i] = 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_tipname'] = tipname_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n",
      "55231\n",
      "0.07857500554837903\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_tipname'].shape[0]\n",
    "print(all_vals)\n",
    "success = df[df['fuzzy_match_for_tipname'] == 1].shape[0]\n",
    "print(success)\n",
    "fuzzyline_tipname = success / all_vals\n",
    "print(fuzzyline_tipname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нечеткий поиск по match_date_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без нграммов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-19 19:00:00 2019-07-19\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-09\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-07-07 22:30:00 2019-07-07\n",
      "2019-03-14 17:55:00 2019-03-14\n",
      "2019-03-14 17:55:00 2019-03-14\n",
      "2019-03-14 17:55:00 2019-03-14\n",
      "2019-03-14 17:55:00 2019-03-14\n",
      "2019-03-07 20:00:00 2019-03-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-04-07 12:00:00 2019-04-07\n",
      "2019-09-05 18:45:00 2019-09-05\n",
      "2019-05-28 16:30:00 2019-05-28\n",
      "2019-10-01 19:00:00 2019-10-01\n",
      "2019-06-06 23:00:00 2019-06-02\n",
      "2019-06-06 23:00:00 2019-06-02\n",
      "2019-06-06 23:00:00 2019-06-04\n",
      "2019-06-06 23:00:00 2019-06-03\n",
      "2019-06-06 23:00:00 2019-06-03\n",
      "2019-06-06 23:00:00 2019-06-04\n",
      "2019-06-06 23:00:00 2019-06-06\n",
      "2019-06-06 23:00:00 2019-06-04\n",
      "2019-06-06 23:00:00 2019-06-07\n",
      "2019-06-06 23:00:00 2019-06-06\n",
      "2019-06-06 23:00:00 2019-06-06\n",
      "2019-06-06 23:00:00 2019-06-06\n",
      "2019-06-06 23:00:00 2019-06-06\n",
      "2019-06-06 23:00:00 2019-06-08\n",
      "2019-06-06 23:00:00 2019-06-07\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-07\n",
      "2019-04-06 16:00:00 2019-04-07\n",
      "2019-04-06 16:00:00 2019-04-07\n",
      "2019-04-06 16:00:00 2019-04-07\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-04-06 16:00:00 2019-04-06\n",
      "2019-02-08 19:30:00 2019-02-08\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-02-24 16:00:00 2019-02-24\n",
      "2019-03-07 17:55:00 2019-03-07\n",
      "2019-03-07 17:55:00 2019-03-07\n",
      "2019-09-07 13:00:00 2019-09-07\n",
      "2019-04-14 18:45:00 2019-04-13\n",
      "2019-04-14 18:45:00 2019-04-13\n",
      "2019-04-14 18:45:00 2019-04-14\n",
      "2019-04-14 18:45:00 2019-04-14\n",
      "2019-04-14 18:45:00 2019-04-14\n",
      "2019-04-14 18:45:00 2019-04-14\n",
      "2019-04-14 18:45:00 2019-04-14\n",
      "2019-04-14 18:45:00 2019-04-14\n",
      "2019-09-08 19:00:00 2019-09-01\n",
      "2019-09-08 19:00:00 2019-09-01\n",
      "2019-09-08 19:00:00 2019-09-01\n",
      "2019-09-08 19:00:00 2019-09-01\n",
      "2019-09-08 19:00:00 2019-09-01\n",
      "2019-09-08 19:00:00 2019-09-01\n",
      "2019-09-08 19:00:00 2019-09-01\n",
      "2019-09-08 19:00:00 2019-09-02\n",
      "2019-09-08 19:00:00 2019-09-02\n",
      "2019-09-08 19:00:00 2019-09-04\n",
      "2019-09-08 19:00:00 2019-09-04\n",
      "2019-09-08 19:00:00 2019-09-05\n",
      "2019-09-08 19:00:00 2019-09-05\n",
      "2019-09-08 19:00:00 2019-09-06\n",
      "2019-09-08 19:00:00 2019-09-06\n",
      "2019-09-08 19:00:00 2019-09-06\n",
      "2019-09-08 19:00:00 2019-09-06\n",
      "2019-09-08 19:00:00 2019-09-06\n",
      "2019-09-08 19:00:00 2019-09-08\n",
      "2019-09-08 19:00:00 2019-09-07\n",
      "2019-09-08 19:00:00 2019-09-08\n",
      "2019-09-08 19:00:00 2019-09-08\n",
      "2019-09-08 19:00:00 2019-09-08\n",
      "2019-09-08 19:00:00 2019-09-08\n",
      "2019-09-08 19:00:00 2019-09-08\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-07\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-10\n",
      "2019-07-09 17:30:00 2019-07-08\n",
      "2019-07-09 17:30:00 2019-07-08\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-10\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-07-09 17:30:00 2019-07-09\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-26\n",
      "2019-06-29 21:00:00 2019-06-27\n",
      "2019-06-29 21:00:00 2019-06-27\n",
      "2019-06-29 21:00:00 2019-06-28\n",
      "2019-06-29 21:00:00 2019-06-27\n",
      "2019-06-29 21:00:00 2019-06-28\n",
      "2019-06-29 21:00:00 2019-06-27\n",
      "2019-06-29 21:00:00 2019-06-27\n",
      "2019-06-29 21:00:00 2019-06-27\n",
      "2019-06-29 21:00:00 2019-06-27\n",
      "2019-06-29 21:00:00 2019-06-28\n",
      "2019-06-29 21:00:00 2019-06-28\n",
      "2019-06-29 21:00:00 2019-06-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-03 11:30:00 2019-09-03\n",
      "2019-09-03 11:30:00 2019-09-02\n",
      "2019-09-03 11:30:00 2019-09-02\n",
      "2019-09-03 11:30:00 2019-09-03\n",
      "2019-09-03 11:30:00 2019-09-03\n",
      "2019-09-03 11:30:00 2019-09-02\n",
      "2019-09-03 11:30:00 2019-09-02\n",
      "2019-09-03 11:30:00 2019-09-02\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-11\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-13\n",
      "2019-07-13 18:30:00 2019-07-14\n",
      "2019-07-13 18:30:00 2019-07-14\n",
      "2019-07-13 18:30:00 2019-07-14\n",
      "2019-07-13 18:30:00 2019-07-12\n",
      "2019-07-13 18:30:00 2019-07-13\n",
      "2019-10-04 19:00:00 2019-10-04\n",
      "2019-10-04 19:00:00 2019-10-04\n",
      "2019-07-06 19:00:00 2019-07-06\n",
      "2019-07-06 19:00:00 2019-07-06\n",
      "2019-07-06 19:00:00 2019-07-06\n",
      "2019-07-06 19:00:00 2019-07-06\n",
      "2019-07-06 19:00:00 2019-07-06\n",
      "2019-09-01 13:00:00 2019-09-01\n",
      "2019-09-01 13:00:00 2019-09-01\n",
      "2019-09-01 13:00:00 2019-09-01\n",
      "2019-09-01 13:00:00 2019-09-01\n",
      "2019-09-01 13:00:00 2019-09-01\n",
      "Wall time: 2h 45min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens = []\n",
    "date_match = np.zeros(df.shape[0])\n",
    "for i, text in enumerate(df['result.tsv'].values):\n",
    "    txt_tokens = []\n",
    "    txt_tokens.append(word_tokenize(text))\n",
    "    for text in txt_tokens:\n",
    "        for t in text:\n",
    "            if fuzz.ratio(df['match_date_time'][i], t) > 60:\n",
    "                date_match[i] = 1\n",
    "                print(df['match_date_time'][i], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_date'] = date_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n",
      "23\n",
      "3.272120960353275e-05\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_date'].shape[0]\n",
    "print(all_vals)\n",
    "success = df[df['fuzzy_match_for_date'] == 1].shape[0]\n",
    "print(success)\n",
    "fuzzyline_date = success / all_vals\n",
    "print(fuzzyline_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нечеткий поиск по коэффициентам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без нграммов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokens = []\n",
    "coef_match = np.zeros(df.shape[0])\n",
    "for i, text in enumerate(df['result.tsv'].values):\n",
    "    txt_tokens = []\n",
    "    txt_tokens.append(word_tokenize(text))\n",
    "    for text in txt_tokens:\n",
    "        for t in text:\n",
    "            if fuzz.ratio(df['odd'][i], t) > 60:\n",
    "                coef_match[i] = 1\n",
    "                #print(df['match_date_time'][i], t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuzzy_match_for_odd'] = coef_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702908\n",
      "3837\n",
      "0.005458751358641529\n"
     ]
    }
   ],
   "source": [
    "all_vals = df['fuzzy_match_for_odd'].shape[0]\n",
    "print(all_vals)\n",
    "success = df[df['fuzzy_match_for_odd'] == 1].shape[0]\n",
    "print(success)\n",
    "fuzzyline_odd = success / all_vals\n",
    "print(fuzzyline_odd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
