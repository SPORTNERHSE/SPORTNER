{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ссылка на главную страницу с футбольными клубами по странам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = urllib.request.urlopen('https://ru.wikipedia.org/wiki/%D0%9A%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D1%8F:%D0%A4%D1%83%D1%82%D0%B1%D0%BE%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D0%BA%D0%BB%D1%83%D0%B1%D1%8B_%D0%BF%D0%BE_%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B0%D0%BC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = r.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = result.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content, 'lxml') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсим ее и получаем ссылки на отдельные страны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in soup.find_all('div', attrs={'class':'CategoryTreeItem'}):\n",
    "    link = div.find('a').get('href')\n",
    "    links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проход по каждой стране"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 180/180 [02:16<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "teams_dict = {}\n",
    "empty_team_lists = [] #список для команд стран с другой структурой страниц\n",
    "empty_team_lists_links = []\n",
    "\n",
    "for link in tqdm(links):\n",
    "    page = urllib.request.urlopen('https://ru.wikipedia.org/' + link) #проходим по каждой ссылке\n",
    "    result = page.read()\n",
    "    content = result.decode('utf-8')\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    for h1 in soup.find_all('h1', attrs={'class':'firstHeading'}): #находим нужный элемент в html \n",
    "        name = h1.get_text() #забираем название, напр: Футбольные клубы Англии\n",
    "        if name.startswith('Категория:'):\n",
    "            norm_name = name.replace('Категория:', '')\n",
    "            \n",
    "    teams_list = []    \n",
    "    for div in soup.find_all('div', attrs={'class':'mw-category-group'}): #находим все команды в этой стране\n",
    "        team_links = div.find_all('a')\n",
    "        for team_link in team_links:\n",
    "            team = team_link.get('title')\n",
    "            #print(team)\n",
    "            if team.startswith('Категория:ФК'):\n",
    "                norm_team = team.replace('Категория:ФК', '')\n",
    "                norm_team = re.sub(r'[«»]','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(спортивное сообщество\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                #norm_team = norm_team.strip(punctuation)\n",
    "            \n",
    "            elif team.startswith('Категория:') or team.startswith('Список'):\n",
    "                    continue\n",
    "                \n",
    "            elif team.endswith('(футбольный клуб)'):\n",
    "                norm_team = team.replace('(футбольный клуб)', '')\n",
    "                norm_team = re.sub(r'[«»]','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(спортивное сообщество\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                #norm_team = norm_team.strip(punctuation)\n",
    "            else:\n",
    "                norm_team = team\n",
    "                norm_team = re.sub(r'[«»]','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(спортивное сообщество\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                #norm_team = norm_team.strip(punctuation)\n",
    "            \n",
    "            teams_list.append(norm_team)\n",
    "    \n",
    "    teams_list1 = teams_list\n",
    "    \n",
    "    teams_list2 = []\n",
    "    second_page_div = soup.find('div', attrs={'id':'mw-pages'})\n",
    "    if second_page_div:\n",
    "        a = second_page_div.find('a')\n",
    "        if a.get_text() == 'Следующая страница':\n",
    "            second_page = a.get('href')\n",
    "            link = 'https://ru.wikipedia.org'+second_page\n",
    "            page2 = urllib.request.urlopen(link)\n",
    "            result2 = page2.read()\n",
    "            content2 = result2.decode('utf-8')\n",
    "            soup2 = BeautifulSoup(content2, 'lxml')\n",
    "            h2 = soup2.find('div', attrs={'id':'mw-pages'})\n",
    "            for a in h2.find_all('a'):\n",
    "                team2 = a.get('title')\n",
    "                #print(team2)\n",
    "                if team2.startswith('Категория:ФК'):\n",
    "                    norm_team2 = team2.replace('Категория:ФК', '')\n",
    "                    norm_team2 = re.sub(r'[«»]','', norm_team2)\n",
    "                    norm_team2 = norm_team2.strip(' ')\n",
    "                    norm_team2 = re.sub(r'\\(футбольный клуб.+\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(футбольный клуб\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(спортивное общество\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(женский футбольный клуб\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team2)\n",
    "                    norm_team2 = norm_team2.strip(' ')\n",
    "                    #norm_team2 = norm_team2.strip(punctuation)\n",
    "                elif team2.startswith('Категория:') or team2.startswith('Список'):\n",
    "                    continue    \n",
    "                elif team.endswith('(футбольный клуб)'):\n",
    "                    norm_team2 = team2.replace('(футбольный клуб)', '')\n",
    "                    norm_team2 = re.sub(r'[«»]','', norm_team2)\n",
    "                    norm_team2 = norm_team2.strip(' ')\n",
    "                    norm_team2 = re.sub(r'\\(футбольный клуб.+\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(футбольный клуб\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(спортивное общество\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(женский футбольный клуб\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team2)\n",
    "                    norm_team2 = norm_team2.strip(' ')\n",
    "                    #norm_team2 = norm_team2.strip(punctuation)\n",
    "                else:\n",
    "                    norm_team2 = team2\n",
    "                    norm_team2 = re.sub(r'[«»]','', norm_team2)\n",
    "                    norm_team2 = norm_team2.strip(' ')\n",
    "                    norm_team2 = re.sub(r'\\(футбольный клуб.+\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(футбольный клуб\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(спортивное общество\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(женский футбольный клуб\\)','', norm_team2)\n",
    "                    norm_team2 = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team2)\n",
    "                    norm_team2 = norm_team2.strip(' ')\n",
    "                    #norm_team2 = norm_team2.strip(punctuation)\n",
    "                #print(norm_team2)\n",
    "                \n",
    "                teams_list2.append(norm_team2)\n",
    "            #print(teams_list2)\n",
    "    \n",
    "    if teams_list2:\n",
    "        full_teams_list = set(teams_list1 + teams_list2)\n",
    "    else:\n",
    "        full_teams_list = set(teams_list1)\n",
    "                \n",
    "\n",
    "    if full_teams_list: #если список с командами не пустой - добавляем в словарь\n",
    "        teams_dict[norm_name] = full_teams_list\n",
    "    else:\n",
    "        empty_team_lists.append(norm_name) #если список команд пустой - добавляем в список с такими же странами\n",
    "        empty_team_lists_links.append(link) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление в словарь оставшихся клубов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:29<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "bad_links = []\n",
    "\n",
    "for link in tqdm(empty_team_lists_links):\n",
    "    #print('https://ru.wikipedia.org' + link)\n",
    "    page = urllib.request.urlopen('https://ru.wikipedia.org' + link) \n",
    "    result = page.read()\n",
    "    content = result.decode('utf-8')\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    for h1 in soup.find_all('h1', attrs={'class':'firstHeading'}): #находим нужный элемент в html \n",
    "        name = h1.get_text() #забираем название, напр: Футбольные клубы Англии\n",
    "        if name.startswith('Категория:'):\n",
    "            norm_name = name.replace('Категория:', '')\n",
    "    \n",
    "    teams_list = []    \n",
    "    for div in soup.find_all('div', attrs={'class':'mw-category-generated'}): #находим все команды в этой стране\n",
    "        #print(div)\n",
    "        team_links = div.find_all('a')\n",
    "        #print(team_links)\n",
    "        for team_link in team_links:\n",
    "            team = team_link.get('title')\n",
    "            if team.startswith('Категория:ФК'):\n",
    "                norm_team = team.replace('Категория:ФК', '') \n",
    "                norm_team = re.sub(r'[«»]','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(спортивное общество\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                \n",
    "            elif team.endswith('(футбольный клуб)'):\n",
    "                norm_team = team.replace('(футбольный клуб)', '')\n",
    "                norm_team = re.sub(r'[«»]','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(спортивное общество\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                \n",
    "            elif team.startswith('Категория:'):\n",
    "                bad_links.append(team_link.get('href'))\n",
    "                #norm_team = norm_team.strip(' ')\n",
    "                \n",
    "            else:\n",
    "                norm_team = team\n",
    "                norm_team = re.sub(r'[«»]','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(спортивное общество\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "                norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "                norm_team = norm_team.strip(' ')\n",
    "                    \n",
    "            teams_list.append(norm_team)\n",
    "    teams_list = set(teams_list)\n",
    "    teams_dict[norm_name] = teams_list\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсинг клубов отдельной страны/города по ссылке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://ru.wikipedia.org/wiki/%D0%9A%D0%B0%D1%82%D0%B5%D0%B3%D0%BE%D1%80%D0%B8%D1%8F:%D0%A4%D1%83%D1%82%D0%B1%D0%BE%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D0%BA%D0%BB%D1%83%D0%B1%D1%8B_%D0%9A%D0%B8%D0%B5%D0%B2%D0%B0'\n",
    "page = urllib.request.urlopen(link) \n",
    "result = page.read()\n",
    "content = result.decode('utf-8')\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "for h1 in soup.find_all('h1', attrs={'class':'firstHeading'}): #находим нужный элемент в html \n",
    "        name = h1.get_text() #забираем название, напр: Футбольные клубы Англии\n",
    "        if name.startswith('Категория:'):\n",
    "            norm_name = name.replace('Категория:', '')\n",
    "            \n",
    "teams_list = []    \n",
    "for div in soup.find_all('div', attrs={'class':'mw-category-generated'}): #находим все команды в этой стране\n",
    "    #print(div)\n",
    "    team_links = div.find_all('a')\n",
    "    #print(team_links)\n",
    "    for team_link in team_links:\n",
    "        team = team_link.get('title')\n",
    "        if team.startswith('Категория:ФК'):\n",
    "            norm_team = team.replace('Категория:ФК', '') \n",
    "            norm_team = re.sub(r'[«»]','', norm_team)\n",
    "            norm_team = norm_team.strip(' ')\n",
    "            norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(спортивное общество\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "            norm_team = norm_team.strip(' ')\n",
    "                \n",
    "        elif team.endswith('(футбольный клуб)'):\n",
    "            norm_team = team.replace('(футбольный клуб)', '')\n",
    "            norm_team = re.sub(r'[«»]','', norm_team)\n",
    "            norm_team = norm_team.strip(' ')\n",
    "            norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(спортивное общество\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "            norm_team = norm_team.strip(' ')\n",
    "                \n",
    "        elif team.startswith('Категория:'):\n",
    "            bad_links.append(team_link.get('href'))\n",
    "            #norm_team = norm_team.strip(' ')\n",
    "                \n",
    "        else:\n",
    "            norm_team = team\n",
    "            norm_team = re.sub(r'[«»]','', norm_team)\n",
    "            norm_team = norm_team.strip(' ')\n",
    "            norm_team = re.sub(r'\\(футбольный клуб.+\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(футбольный клуб\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(спортивное общество\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(женский футбольный клуб\\)','', norm_team)\n",
    "            norm_team = re.sub(r'\\(женский футбольный клуб.+\\)','', norm_team)\n",
    "            norm_team = norm_team.strip(' ')\n",
    "                    \n",
    "        teams_list.append(norm_team)\n",
    "teams_list = set(teams_list)\n",
    "teams_dict[norm_name] = teams_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_teams = [*teams_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_teams = []\n",
    "for team_set in list_teams:\n",
    "    for team in team_set:\n",
    "        count_teams.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_teams = set(count_teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мэтч по своему списку команд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "punct = punctuation+'©«»—…“”*№–'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('result_tar.gz', compression='gzip', sep='\\t', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"url\", \"video_url\", \"source_name\", \"author_name\"], axis=1)\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_language (text):\n",
    "    if bool(re.search('[\\u0400-\\u04FF]', text)) == True:\n",
    "        return 'russian'\n",
    "    else:\n",
    "        return 'english'\n",
    "    \n",
    "lang=[]\n",
    "for i,text in enumerate(df['result.tsv'].values): \n",
    "    lang.append(which_language(str(text)))\n",
    "    \n",
    "df['Language'] = lang\n",
    "grouped=df.groupby('Language')\n",
    "for name, group in grouped: \n",
    "    if name == 'english': \n",
    "        english = group.drop('Language',axis=1) \n",
    "    else: \n",
    "        russian = group.drop('Language',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian = russian.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams1_match = np.zeros(russian.shape[0])\n",
    "teams2_match = np.zeros(russian.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(russian['result.tsv'].values):\n",
    "    txt_tokens = []\n",
    "    txt_tokens.append(word_tokenize(text))\n",
    "    for txt in txt_tokens:\n",
    "        count_tokens = []\n",
    "        for token in txt:\n",
    "            token = token.strip(punct)\n",
    "            if token in uniq_teams:\n",
    "                count_tokens.append(token)\n",
    "        c = Counter(count_tokens)\n",
    "        \n",
    "        try: \n",
    "            max_w1 = sorted(c, key=c.get)[-1]\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            max_w2 = sorted(c, key=c.get)[-2]\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if russian['team_of_season_1_name_in_russian'][i] == max_w1 or russian['team_of_season_1_name_in_russian'][i] == max_w2:\n",
    "            teams1_match[i] = 1\n",
    "\n",
    "        \n",
    "        if russian['team_of_season_2_name_in_russian'][i] == max_w1 or russian['team_of_season_2_name_in_russian'][i] == max_w2:\n",
    "            teams2_match[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian['list_direct_match_for_teams1'] = teams1_match\n",
    "russian['list_direct_match_for_teams2'] = teams2_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17921537896165832\n",
      "0.1814253663595282\n"
     ]
    }
   ],
   "source": [
    "success1 = russian[russian['list_direct_match_for_teams1'] == 1].shape[0]\n",
    "success2 = russian[russian['list_direct_match_for_teams2'] == 1].shape[0]\n",
    "\n",
    "all_vals = russian['list_direct_match_for_teams1'].shape[0]\n",
    "\n",
    "result_team1 = success1 / all_vals\n",
    "print(result_team1)\n",
    "\n",
    "result_team2 = success2 / all_vals\n",
    "print(result_team2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian.to_csv(r'C:\\Users\\User\\Desktop\\project\\russian_custom_lists_and_directmatch.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
